{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 15:19:21.495423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-04 15:19:21.662531: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-04 15:19:21.662594: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-04 15:19:21.861050: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 15:19:31.052952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import sys, os, time, warnings, pdb, pickle, random, math, re, json\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.insert(0, '../scripts')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Dropout, CategoryEncoding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import metrics\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set_style(\"darkgrid\")\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PS_20174392719_1491204439457_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nameOrig  nameDest\n",
      "0    757869   1662094\n",
      "1   2188998   1733924\n",
      "2   1002156    439685\n",
      "3   5828262    391696\n",
      "4   3445981    828919\n"
     ]
    }
   ],
   "source": [
    "df['diff_orig'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n",
    "df['diff_dest'] = df['oldbalanceDest'] - df['newbalanceDest']\n",
    "df['amount_percentage'] = df['amount'] / (df['oldbalanceOrg'] + 1e-9)\n",
    "df['step'] = df['step'] % 24\n",
    "\n",
    "# Initialize LabelEncoder for nameOrig, nameDest, and type\n",
    "label_encoder_orig = LabelEncoder()\n",
    "label_encoder_dest = LabelEncoder()\n",
    "label_encoder_type = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the nameOrig and nameDest columns\n",
    "df['nameOrig'] = label_encoder_orig.fit_transform(df['nameOrig'])\n",
    "df['nameDest'] = label_encoder_dest.fit_transform(df['nameDest'])\n",
    "df['type'] = label_encoder_type.fit_transform(df['type'])\n",
    "\n",
    "# Check the result\n",
    "print(df[['nameOrig', 'nameDest']].head())\n",
    "\n",
    "# Train-test split\n",
    "y = df['isFraud']\n",
    "X = df.drop(['isFraud', 'isFlaggedFraud'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'diff_orig', 'diff_dest', 'amount_percentage']] = scaler.fit_transform(\n",
    "    X_train[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'diff_orig', 'diff_dest', 'amount_percentage']])\n",
    "X_test[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'diff_orig', 'diff_dest', 'amount_percentage']] = scaler.transform(\n",
    "    X_test[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'diff_orig', 'diff_dest', 'amount_percentage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 15:20:44.670899: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-04 15:20:44.671504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-04 15:20:44.672037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-04 15:20:44.672595: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-04 15:20:44.673153: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-04 15:20:44.673722: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-04 15:20:45.184245: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 5090096 entries, 292779 to 1541412\n",
      "Series name: isFraud\n",
      "Non-Null Count    Dtype\n",
      "--------------    -----\n",
      "5090096 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 77.7 MB\n",
      "None\n",
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 569ms/step - Brier score: 0.1551 - accuracy: 0.7866 - auc: 0.8333 - cross entropy: 0.4984 - fn: 615.3571 - fp: 355571.7500 - loss: 0.5418 - prc: 0.0786 - precision: 0.0052 - recall: 0.7440 - tn: 1721819.5000 - tp: 2121.5635 - val_Brier score: 0.0357 - val_accuracy: 0.9651 - val_auc: 0.9816 - val_cross entropy: 0.1454 - val_fn: 143.0000 - val_fp: 35357.0000 - val_loss: 0.1454 - val_prc: 0.4031 - val_precision: 0.0312 - val_recall: 0.8885 - val_tn: 981381.0000 - val_tp: 1139.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 535ms/step - Brier score: 0.0544 - accuracy: 0.9309 - auc: 0.9751 - cross entropy: 0.1914 - fn: 225.0556 - fp: 139267.4375 - loss: 0.2033 - prc: 0.2766 - precision: 0.0171 - recall: 0.9126 - tn: 1938147.8750 - tp: 2487.8491 - val_Brier score: 0.0311 - val_accuracy: 0.9627 - val_auc: 0.9880 - val_cross entropy: 0.1145 - val_fn: 101.0000 - val_fp: 37894.0000 - val_loss: 0.1145 - val_prc: 0.4427 - val_precision: 0.0302 - val_recall: 0.9212 - val_tn: 978844.0000 - val_tp: 1181.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 613ms/step - Brier score: 0.0292 - accuracy: 0.9637 - auc: 0.9922 - cross entropy: 0.1066 - fn: 92.9841 - fp: 69657.6562 - loss: 0.1089 - prc: 0.4206 - precision: 0.0341 - recall: 0.9600 - tn: 2007764.6250 - tp: 2612.8889 - val_Brier score: 0.0162 - val_accuracy: 0.9786 - val_auc: 0.9831 - val_cross entropy: 0.0574 - val_fn: 177.0000 - val_fp: 21585.0000 - val_loss: 0.0574 - val_prc: 0.4221 - val_precision: 0.0487 - val_recall: 0.8619 - val_tn: 995153.0000 - val_tp: 1105.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 610ms/step - Brier score: 0.0042 - accuracy: 0.9950 - auc: 0.9996 - cross entropy: 0.0184 - fn: 12.4683 - fp: 9108.0479 - loss: 0.0195 - prc: 0.8360 - precision: 0.2101 - recall: 0.9949 - tn: 2068346.5000 - tp: 2661.1746 - val_Brier score: 0.0092 - val_accuracy: 0.9882 - val_auc: 0.9599 - val_cross entropy: 0.0347 - val_fn: 277.0000 - val_fp: 11693.0000 - val_loss: 0.0347 - val_prc: 0.3263 - val_precision: 0.0791 - val_recall: 0.7839 - val_tn: 1005045.0000 - val_tp: 1005.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 591ms/step - Brier score: 7.2584e-04 - accuracy: 0.9992 - auc: 0.9999 - cross entropy: 0.0042 - fn: 2.7540 - fp: 1634.9207 - loss: 0.0055 - prc: 0.9549 - precision: 0.6083 - recall: 0.9986 - tn: 2075814.2500 - tp: 2676.2698 - val_Brier score: 0.0074 - val_accuracy: 0.9907 - val_auc: 0.9457 - val_cross entropy: 0.0293 - val_fn: 311.0000 - val_fp: 9185.0000 - val_loss: 0.0293 - val_prc: 0.3001 - val_precision: 0.0956 - val_recall: 0.7574 - val_tn: 1007553.0000 - val_tp: 971.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 606ms/step - Brier score: 2.8750e-04 - accuracy: 0.9997 - auc: 0.9999 - cross entropy: 0.0020 - fn: 1.2619 - fp: 655.9445 - loss: 0.0027 - prc: 0.9751 - precision: 0.8138 - recall: 0.9997 - tn: 2076756.7500 - tp: 2714.2698 - val_Brier score: 0.0071 - val_accuracy: 0.9911 - val_auc: 0.9379 - val_cross entropy: 0.0287 - val_fn: 323.0000 - val_fp: 8755.0000 - val_loss: 0.0287 - val_prc: 0.2803 - val_precision: 0.0987 - val_recall: 0.7480 - val_tn: 1007983.0000 - val_tp: 959.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 607ms/step - Brier score: 1.6122e-04 - accuracy: 0.9998 - auc: 0.9998 - cross entropy: 0.0013 - fn: 1.3730 - fp: 355.7460 - loss: 0.0035 - prc: 0.9896 - precision: 0.8894 - recall: 0.9994 - tn: 2077076.5000 - tp: 2694.6111 - val_Brier score: 0.0086 - val_accuracy: 0.9893 - val_auc: 0.9366 - val_cross entropy: 0.0364 - val_fn: 317.0000 - val_fp: 10611.0000 - val_loss: 0.0364 - val_prc: 0.2208 - val_precision: 0.0834 - val_recall: 0.7527 - val_tn: 1006127.0000 - val_tp: 965.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 606ms/step - Brier score: 1.3953e-04 - accuracy: 0.9999 - auc: 0.9997 - cross entropy: 0.0011 - fn: 0.9365 - fp: 285.3968 - loss: 0.0027 - prc: 0.9900 - precision: 0.9001 - recall: 0.9995 - tn: 2077155.7500 - tp: 2686.1587 - val_Brier score: 0.0072 - val_accuracy: 0.9910 - val_auc: 0.9272 - val_cross entropy: 0.0313 - val_fn: 349.0000 - val_fp: 8767.0000 - val_loss: 0.0313 - val_prc: 0.2364 - val_precision: 0.0962 - val_recall: 0.7278 - val_tn: 1007971.0000 - val_tp: 933.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 604ms/step - Brier score: 7.0247e-05 - accuracy: 0.9999 - auc: 0.9999 - cross entropy: 6.0982e-04 - fn: 0.5317 - fp: 157.6032 - loss: 0.0013 - prc: 0.9958 - precision: 0.9478 - recall: 0.9999 - tn: 2077275.5000 - tp: 2694.5159 - val_Brier score: 0.0095 - val_accuracy: 0.9882 - val_auc: 0.9296 - val_cross entropy: 0.0419 - val_fn: 318.0000 - val_fp: 11657.0000 - val_loss: 0.0419 - val_prc: 0.1886 - val_precision: 0.0764 - val_recall: 0.7520 - val_tn: 1005081.0000 - val_tp: 964.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 603ms/step - Brier score: 5.9993e-05 - accuracy: 0.9999 - auc: 1.0000 - cross entropy: 5.6008e-04 - fn: 0.2381 - fp: 119.5714 - loss: 6.0862e-04 - prc: 0.9959 - precision: 0.9549 - recall: 0.9999 - tn: 2077319.0000 - tp: 2689.3889 - val_Brier score: 0.0080 - val_accuracy: 0.9901 - val_auc: 0.9216 - val_cross entropy: 0.0363 - val_fn: 347.0000 - val_fp: 9702.0000 - val_loss: 0.0363 - val_prc: 0.2016 - val_precision: 0.0879 - val_recall: 0.7293 - val_tn: 1007036.0000 - val_tp: 935.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 605ms/step - Brier score: 4.5821e-05 - accuracy: 1.0000 - auc: 1.0000 - cross entropy: 4.1707e-04 - fn: 0.1032 - fp: 86.3016 - loss: 2.9337e-04 - prc: 0.9963 - precision: 0.9644 - recall: 1.0000 - tn: 2077353.6250 - tp: 2688.1270 - val_Brier score: 0.0078 - val_accuracy: 0.9904 - val_auc: 0.9183 - val_cross entropy: 0.0360 - val_fn: 354.0000 - val_fp: 9394.0000 - val_loss: 0.0360 - val_prc: 0.1988 - val_precision: 0.0899 - val_recall: 0.7239 - val_tn: 1007344.0000 - val_tp: 928.0000\n",
      "\u001b[1m39767/39767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1ms/step\n",
      "[[1259725   11156]\n",
      " [    402    1241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00   1270881\n",
      "           1       0.10      0.76      0.18      1643\n",
      "\n",
      "    accuracy                           0.99   1272524\n",
      "   macro avg       0.55      0.87      0.59   1272524\n",
      "weighted avg       1.00      0.99      0.99   1272524\n",
      "\n",
      "AUC-ROC: 0.9784340000854277\n"
     ]
    }
   ],
   "source": [
    "# Model with embedding layers for nameOrig and nameDest\n",
    "input_step = Input(shape=(1,))\n",
    "input_amount = Input(shape=(1,))\n",
    "input_oldbalanceOrg = Input(shape=(1,))\n",
    "input_newbalanceOrig = Input(shape=(1,))\n",
    "input_oldbalanceDest = Input(shape=(1,))\n",
    "input_newbalanceDest = Input(shape=(1,))\n",
    "input_diff_orig = Input(shape=(1,))\n",
    "input_diff_dest = Input(shape=(1,))\n",
    "input_amount_percentage = Input(shape=(1,))\n",
    "input_type = Input(shape=(1,))\n",
    "input_nameOrig = Input(shape=(1,))\n",
    "input_nameDest = Input(shape=(1,))\n",
    "\n",
    "# Embedding layers for nameOrig and nameDest\n",
    "embedding_size = 16\n",
    "\n",
    "embedding_nameOrig = Embedding(input_dim=np.max(X_train['nameOrig']) + 1, output_dim=embedding_size)(input_nameOrig)\n",
    "embedding_nameDest = Embedding(input_dim=np.max(X_train['nameDest']) + 1, output_dim=embedding_size)(input_nameDest)\n",
    "\n",
    "one_hot_type = CategoryEncoding(num_tokens=5, output_mode=\"one_hot\")(input_type)\n",
    "\n",
    "# Flatten embedding layers\n",
    "flatten_nameOrig = Flatten()(embedding_nameOrig)\n",
    "flatten_nameDest = Flatten()(embedding_nameDest)\n",
    "\n",
    "# Concatenate all features\n",
    "concatenated = Concatenate()([\n",
    "    input_step,\n",
    "    input_amount, \n",
    "    input_oldbalanceOrg, \n",
    "    input_newbalanceOrig, \n",
    "    input_oldbalanceDest, \n",
    "    input_newbalanceDest, \n",
    "    input_diff_orig, \n",
    "    input_diff_dest, \n",
    "    input_amount_percentage, \n",
    "    one_hot_type, \n",
    "    flatten_nameOrig, \n",
    "    flatten_nameDest\n",
    "])\n",
    "\n",
    "# Hidden layers\n",
    "dense_1 = Dense(256, activation='relu')(concatenated)\n",
    "dense_2 = Dense(256, activation='relu')(dense_1)\n",
    "dropout1 = Dropout(0.5)(dense_1)\n",
    "dense_3 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense_3)\n",
    "output = Dense(1, activation='sigmoid')(dropout2)\n",
    "\n",
    "# Build and compile model\n",
    "model = Model(inputs=[\n",
    "    input_step,\n",
    "    input_amount, \n",
    "    input_oldbalanceOrg, \n",
    "    input_newbalanceOrig, \n",
    "    input_oldbalanceDest, \n",
    "    input_newbalanceDest, \n",
    "    input_diff_orig, \n",
    "    input_diff_dest, \n",
    "    input_amount_percentage, \n",
    "    input_type, \n",
    "    input_nameOrig, \n",
    "    input_nameDest\n",
    "], outputs=output)\n",
    "\n",
    "METRICS = [\n",
    "      metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "      metrics.MeanSquaredError(name='Brier score'),\n",
    "      metrics.TruePositives(name='tp'),\n",
    "      metrics.FalsePositives(name='fp'),\n",
    "      metrics.TrueNegatives(name='tn'),\n",
    "      metrics.FalseNegatives(name='fn'),\n",
    "      metrics.BinaryAccuracy(name='accuracy'),\n",
    "      metrics.Precision(name='precision'),\n",
    "      metrics.Recall(name='recall'),\n",
    "      metrics.AUC(name='auc'),\n",
    "      metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "# Class weights to handle imbalance\n",
    "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(weights))\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train['step'],\n",
    "     X_train['amount'], \n",
    "     X_train['oldbalanceOrg'], \n",
    "     X_train['newbalanceOrig'], \n",
    "     X_train['oldbalanceDest'], \n",
    "     X_train['newbalanceDest'], \n",
    "     X_train['diff_orig'], \n",
    "     X_train['diff_dest'], \n",
    "     X_train['amount_percentage'], \n",
    "     X_train['type'], \n",
    "     X_train['nameOrig'], \n",
    "     X_train['nameDest']], \n",
    "    np.expand_dims(y_train.values, -1), \n",
    "    validation_split=0.2, \n",
    "    epochs=50, \n",
    "    batch_size=8192*4, \n",
    "    class_weight=class_weights, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict([\n",
    "    X_test['step'],\n",
    "    X_test['amount'], \n",
    "    X_test['oldbalanceOrg'], \n",
    "    X_test['newbalanceOrig'], \n",
    "    X_test['oldbalanceDest'], \n",
    "    X_test['newbalanceDest'], \n",
    "    X_test['diff_orig'], \n",
    "    X_test['diff_dest'], \n",
    "    X_test['amount_percentage'], \n",
    "    X_test['type'], \n",
    "    X_test['nameOrig'], \n",
    "    X_test['nameDest']\n",
    "])\n",
    "\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_binary))\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
